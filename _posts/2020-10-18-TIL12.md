---
layout: post
title:  "2019-10-17 TIL"
date:   2020-10-17 23:43
category: today i learned
icon: 
keywords: 
image: study.jpg
preview: 0
---


# 유튜브 강의

- [ 머신러닝 강의 - 2 ] Regularization  
https://www.youtube.com/watch?v=9xpIj5-FdXE&feature=emb_logo

    - L1 distance가 manhathan distance라고 불리게 된 이유가, 좌표가 이동하는게 마치 계획도시인 맨하탄의 블럭을 이동하는 같아서 라고함(카더라)

    - 람다항은 complexity를 줄이기 위해 추가하는 것
    - weight가 오버피팅 되면 확 커지는 경향이 있음
    - 어떤 제약조건을 준다면 오버피팅을 방지할 수 있을 것 

# 블로그
- 선형 회귀(linear regression) 그리고 라쏘 (Lasso)  
https://bskyvision.com/193
    - Lasso는 MSE + penalty = MSE + a*L1_norm
    - Ridge는 MSE + penalty = MSE + a*L2_norm

    - 통계학에서 나오는 용어들인거 같은데 기존에 딥러닝 책에서 나온 내용들이랑 표기가 조금 달라서 이해가 힘들었음. 내용은 비슷한듯
        - OLS(Ordinary Least Square) estimate: 각각의 오차의 제곱합을 구하고, 이를 최소화하는 beta를 구하는 것
        -
